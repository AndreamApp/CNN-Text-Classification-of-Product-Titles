    train_mode = 'CHAR'     # 训练模式，'CHAR'为字符级，'WORD'为词级

    class_num = 1258        # 输出类别的数目
    embedding_dim = 128      # 词向量维度
    filter_num = 300        # 卷积核数目
    filter_sizes = [2, 3, 4]         # 卷积核尺寸
    vocab_size = preprocess.VOCAB_SIZE      # 词汇表大小

    dense_unit_num = 512        # 全连接层神经元

    dropout_keep_prob = 0.5     # dropout保留比例（弃用）
    learning_rate = 1e-3    # 学习率

    train_batch_size = 128         # 每批训练大小
    valid_batch_size = 3000       # 每批验证大小
    test_batch_size = 5000        # 每批测试大小
    valid_per_batch = 500           # 每多少批进行一次验证
    epoch_num = 30001        # 总迭代轮次
valid 92.0%

   train_mode = 'CHAR'     # 训练模式，'CHAR'为字符级，'WORD'为词级

    class_num = 1258        # 输出类别的数目
    embedding_dim = 128      # 词向量维度
    filter_num = 300        # 卷积核数目
    filter_sizes = [1, 2, 3, 4, 5]         # 卷积核尺寸
    vocab_size = preprocess.VOCAB_SIZE      # 词汇表大小

    dense_unit_num = 512        # 全连接层神经元

    dropout_keep_prob = 0.5     # dropout保留比例（弃用）
    learning_rate = 1e-3    # 学习率

    train_batch_size = 128         # 每批训练大小
    valid_batch_size = 3000       # 每批验证大小
    test_batch_size = 5000        # 每批测试大小
    valid_per_batch = 500           # 每多少批进行一次验证
    epoch_num = 30001        # 总迭代轮次
valid 93%

    train_mode = 'WORD'     # 训练模式，'CHAR'为字符级，'WORD'为词级

    class_num = 1258        # 输出类别的数目
    embedding_dim = 128      # 词向量维度，'CHAR'模式适用，
                            # 'WORD'模式默认为preprocess.py中定义的vec_dim

    filter_num = 300        # 卷积核数目
    filter_sizes = [1, 2, 3]         # 卷积核尺寸
    vocab_size = preprocess.VOCAB_SIZE      # 词汇表大小

    dense_unit_num = 512        # 全连接层神经元

    dropout_keep_prob = 0.5     # dropout保留比例（弃用）
    learning_rate = 1e-3    # 学习率

    train_batch_size = 128         # 每批训练大小
    valid_batch_size = 3000       # 每批验证大小
    test_batch_size = 5000        # 每批测试大小
    valid_per_batch = 500           # 每多少批进行一次验证
    epoch_num = 25001        # 总迭代轮次
valid 90%